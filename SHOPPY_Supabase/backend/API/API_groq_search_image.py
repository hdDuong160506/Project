import os
import requests
import base64
import re
from dotenv import load_dotenv
from supabase import create_client, Client
from difflib import SequenceMatcher

load_dotenv()

# Groq API - MI·ªÑN PH√ç & C·ª∞C NHANH
GROQ_SEARCH_IMAGE_API_KEY = os.getenv("GROQ_SEARCH_IMAGE_API_KEY")
VISION_MODEL = "llama-3.2-90b-vision-preview"  # Model vision th·ª±c t·∫ø available

# Supabase
DATA_BASE_SECRET_KEY_SUPABASE = os.getenv("DATA_BASE_SECRET_KEY_SUPABASE")
DATA_BASE_URL_SUPABASE = os.getenv("DATA_BASE_URL_SUPABASE")

url = DATA_BASE_URL_SUPABASE
key = DATA_BASE_SECRET_KEY_SUPABASE
supabase: Client = create_client(url, key)


# ==================== HELPER FUNCTIONS ====================

def fetch_product_names():
    """L·∫•y danh s√°ch t√™n product t·ª´ Supabase"""
    try:
        response = supabase.table("product").select("name").execute()
        rows = response.data
        if not rows:
            print("‚ö†Ô∏è D·ªØ li·ªáu r·ªóng t·ª´ Supabase")
            return []

        names = {row["name"].strip() for row in rows if row.get("name")}
        return list(names)

    except Exception as e:
        print(f"‚ö†Ô∏è Exception fetch_product_names: {e}")
        return []


def normalize_text(text: str) -> str:
    """Chu·∫©n h√≥a text ƒë·ªÉ so s√°nh"""
    text = text.lower().strip()
    text = re.sub(r'[^\w\s√†√°·∫°·∫£√£√¢·∫ß·∫•·∫≠·∫©·∫´ƒÉ·∫±·∫Ø·∫∑·∫≥·∫µ√®√©·∫π·∫ª·∫Ω√™·ªÅ·∫ø·ªá·ªÉ·ªÖ√¨√≠·ªã·ªâƒ©√≤√≥·ªç·ªè√µ√¥·ªì·ªë·ªô·ªï·ªó∆°·ªù·ªõ·ª£·ªü·ª°√π√∫·ª•·ªß≈©∆∞·ª´·ª©·ª±·ª≠·ªØ·ª≥√Ω·ªµ·ª∑·ªπƒë]', '', text)
    return text


def fuzzy_match_product(detected_text: str, products: list) -> str:
    """
    So s√°nh m·ªù ƒë·ªÉ t√¨m s·∫£n ph·∫©m ph√π h·ª£p nh·∫•t
    """
    detected_normalized = normalize_text(detected_text)
    
    print(f"üîç ƒêang t√¨m ki·∫øm cho: '{detected_normalized}'")
    
    best_match = None
    best_score = 0.0
    
    for product in products:
        product_normalized = normalize_text(product)
        
        # Ph∆∞∆°ng ph√°p 1: Ki·ªÉm tra substring
        if detected_normalized in product_normalized or product_normalized in detected_normalized:
            score = 0.9
            print(f"  ‚úì Substring match: '{product}' (score: {score})")
            if score > best_score:
                best_score = score
                best_match = product
        
        # Ph∆∞∆°ng ph√°p 2: Ki·ªÉm tra t·ª´ng t·ª´
        detected_words = set(detected_normalized.split())
        product_words = set(product_normalized.split())
        
        if detected_words & product_words:
            common_ratio = len(detected_words & product_words) / max(len(detected_words), len(product_words))
            if common_ratio > 0.5 and common_ratio > best_score:
                best_score = common_ratio
                best_match = product
                print(f"  ‚úì Word match: '{product}' (score: {common_ratio:.2f})")
        
        # Ph∆∞∆°ng ph√°p 3: Similarity score
        similarity = SequenceMatcher(None, detected_normalized, product_normalized).ratio()
        if similarity > 0.6 and similarity > best_score:
            best_score = similarity
            best_match = product
            print(f"  ‚úì Fuzzy match: '{product}' (score: {similarity:.2f})")
    
    if best_match:
        print(f"‚úÖ Best match: '{best_match}' (score: {best_score:.2f})")
    else:
        print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y match cho '{detected_text}'")
    
    return best_match


def prepare_image_data(image_data: str):
    """
    Chu·∫©n b·ªã image data cho Groq API (base64)
    Returns: (base64_string, mime_type) ho·∫∑c (None, None)
    """
    try:
        # N·∫øu l√† URL
        if image_data.startswith('http://') or image_data.startswith('https://'):
            response = requests.get(image_data, timeout=10)
            if response.status_code == 200:
                base64_data = base64.b64encode(response.content).decode('utf-8')
                mime_type = response.headers.get('Content-Type', 'image/jpeg')
                return base64_data, mime_type
        
        # N·∫øu l√† base64 string v·ªõi data URL
        elif image_data.startswith('data:image'):
            match = re.match(r'data:([^;]+);base64,(.+)', image_data)
            if match:
                mime_type = match.group(1)
                base64_data = match.group(2)
                return base64_data, mime_type
        
        # N·∫øu l√† raw base64 (kh√¥ng c√≥ prefix)
        else:
            return image_data, "image/jpeg"
        
        return None, None
        
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói prepare_image_data: {str(e)}")
        return None, None


def safe_extract_text_from_groq_response(response_data: dict):
    """
    Tr√≠ch xu·∫•t text t·ª´ response Groq m·ªôt c√°ch an to√†n
    """
    try:
        if not response_data:
            return None
        
        # Ki·ªÉm tra error
        if "error" in response_data:
            error = response_data["error"]
            print(f"‚ö†Ô∏è Groq API error: {error.get('message', 'Unknown error')}")
            return None
        
        # L·∫•y content t·ª´ choices
        if "choices" in response_data and response_data["choices"]:
            choice = response_data["choices"][0]
            
            # Ki·ªÉm tra finish_reason
            finish_reason = choice.get("finish_reason")
            if finish_reason and finish_reason not in ["stop", "length"]:
                print(f"‚ö†Ô∏è Groq finish_reason: {finish_reason}")
            
            # L·∫•y text
            if "message" in choice and "content" in choice["message"]:
                text = choice["message"]["content"].strip()
                if text:
                    print(f"‚úÖ Extracted text: {text}")
                    return text
        
        return None
        
    except Exception as e:
        print(f"‚ö†Ô∏è Error parsing Groq response: {e}")
        return None


def clean_detected_text(text: str) -> str:
    """
    L√†m s·∫°ch text t·ª´ AI response
    """
    if not text:
        return ""
    
    # L√†m s·∫°ch k√Ω t·ª± ƒë·∫∑c bi·ªát
    text = text.replace('"', '').replace('*', '').replace('`', '').strip()
    
    # X·ª≠ l√Ω c√°c format c√≥ th·ªÉ c√≥
    if ":" in text:
        text = text.split(":")[-1].strip()
    if "\n" in text:
        text = text.split("\n")[0].strip()
    
    # Lo·∫°i b·ªè c√°c t·ª´ th·ª´a
    stop_words = ["output", "result", "product", "m√≥n", "l√†", "is", "answer", ":", "t√™n", "s·∫£n ph·∫©m"]
    for word in stop_words:
        if text.lower().startswith(word):
            text = text[len(word):].strip()
    
    return text


# ==================== MAIN FUNCTION ====================

def groq_search_product_by_image(image_data: str):
    """
    T√¨m s·∫£n ph·∫©m b·∫±ng h√¨nh ·∫£nh s·ª≠ d·ª•ng Groq Vision API
    
    Args:
        image_data: URL ·∫£nh, base64 string, ho·∫∑c data URL
    
    Returns:
        str: T√™n s·∫£n ph·∫©m t√¨m ƒë∆∞·ª£c, ho·∫∑c None n·∫øu kh√¥ng t√¨m th·∫•y
    """
    # B∆∞·ªõc 1: L·∫•y danh s√°ch s·∫£n ph·∫©m
    products = fetch_product_names()
    
    if not products:
        print("‚ö†Ô∏è Danh s√°ch s·∫£n ph·∫©m r·ªóng")
        return None
    
    if not GROQ_SEARCH_IMAGE_API_KEY:
        print("‚ö†Ô∏è Thi·∫øu GROQ_SEARCH_IMAGE_API_KEY")
        return None
    
    # B∆∞·ªõc 2: Chu·∫©n b·ªã image data
    base64_image, mime_type = prepare_image_data(image_data)
    
    if not base64_image:
        print("‚ö†Ô∏è Kh√¥ng th·ªÉ x·ª≠ l√Ω image data")
        return None
    
    # B∆∞·ªõc 3: T·∫°o prompt
    product_list = ", ".join(products)
    
    prompt = f"""Nh·∫≠n di·ªán ƒë·ªëi t∆∞·ª£ng trong ·∫£nh v√† ch·ªçn T√äN PH√ô H·ª¢P NH·∫§T t·ª´ danh s√°ch s·∫£n ph·∫©m sau:

{product_list}

QUY T·∫ÆC:
1. Nh·∫≠n di·ªán B·∫§T K·ª≤ ƒë·ªëi t∆∞·ª£ng n√†o: ƒë·ªì ƒÉn, th·ª©c u·ªëng, ƒë·ªì d√πng h·ªçc t·∫≠p, thi·∫øt b·ªã ƒëi·ªán t·ª≠, qu·∫ßn √°o, ph·ª• ki·ªán, ƒë·ªì gia d·ª•ng, v.v.
2. Tr·∫£ v·ªÅ ƒê√öNG T√äN t·ª´ danh s√°ch tr√™n (gi·ªØ nguy√™n ch√≠nh t·∫£)
3. N·∫øu l√† ƒë·ªì ƒÉn ‚Üí t√¨m m√≥n ƒÉn t∆∞∆°ng ·ª©ng
4. N·∫øu l√† ƒë·ªì v·∫≠t ‚Üí t√¨m s·∫£n ph·∫©m m√¥ t·∫£ ƒë√∫ng nh·∫•t  
5. N·∫øu l√† thi·∫øt b·ªã ‚Üí t√¨m thi·∫øt b·ªã ƒëi·ªán t·ª≠ ph√π h·ª£p
6. N·∫øu l√† qu·∫ßn √°o ‚Üí t√¨m trang ph·ª•c t∆∞∆°ng t·ª±
7. CH·ªà tr·∫£ v·ªÅ T√äN S·∫¢N PH·∫®M, kh√¥ng gi·∫£i th√≠ch

Output: [t√™n s·∫£n ph·∫©m ch√≠nh x√°c]"""
    
    # B∆∞·ªõc 4: G·ªçi Groq Vision API
    url = "https://api.groq.com/openai/v1/chat/completions"
    
    headers = {
        "Authorization": f"Bearer {GROQ_SEARCH_IMAGE_API_KEY}",
        "Content-Type": "application/json"
    }
    
    data = {
        "model": VISION_MODEL,
        "messages": [
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": prompt
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:{mime_type};base64,{base64_image}"
                        }
                    }
                ]
            }
        ],
        "temperature": 0.2,
        "max_tokens": 500
    }
    
    try:
        response = requests.post(url, headers=headers, json=data, timeout=20)
        
        print(f"üîç Vision API Status: {response.status_code}")
        
        if response.status_code != 200:
            print(f"‚ö†Ô∏è API error {response.status_code}: {response.text}")
            return None
        
        res = response.json()
        print(f"üîç Groq Response: {res}")
        
        # B∆∞·ªõc 5: Tr√≠ch xu·∫•t text
        text = safe_extract_text_from_groq_response(res)
        
        if not text:
            print("‚ö†Ô∏è Kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c text t·ª´ response")
            return None
        
        # B∆∞·ªõc 6: L√†m s·∫°ch text
        text = clean_detected_text(text)
        print(f"‚úÖ Groq Vision detected: '{text}'")
        
        # B∆∞·ªõc 7: Fuzzy matching
        matched_product = fuzzy_match_product(text, products)
        
        if matched_product:
            return matched_product
        
        # B∆∞·ªõc 8: Fallback - t√¨m m√≥n c√≥ ch·ª©a t·ª´ kh√≥a ch√≠nh
        keywords = ["c∆°m", "ph·ªü", "b√∫n", "b√°nh", "ch·∫£", "g√†", "b√≤", "heo"]
        for keyword in keywords:
            if keyword in text.lower():
                for product in products:
                    if keyword in product.lower():
                        print(f"‚ö†Ô∏è Fallback match: {product}")
                        return product
        
        print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p")
        return None
        
    except requests.exceptions.Timeout:
        print("‚ö†Ô∏è Timeout khi g·ªçi Vision API")
        return None
    
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói Vision API: {type(e).__name__} - {str(e)}")
        return None


# ==================== TEST FUNCTION ====================

if __name__ == "__main__":
    # Test v·ªõi URL ·∫£nh
    test_url = "https://example.com/food.jpg"
    print("üñºÔ∏è Test: T√¨m ki·∫øm t·ª´ URL ·∫£nh")
    result = groq_search_product_by_image(test_url)
    print(f"‚û°Ô∏è Result: {result}\n{'-'*50}\n")
    
    # Test v·ªõi base64
    # v·ªõi file local, b·∫°n c√≥ th·ªÉ ƒë·ªçc v√† encode:
    # with open("path/to/image.jpg", "rb") as f:
    #     base64_data = base64.b64encode(f.read()).decode('utf-8')
    #     result = groq_search_product_by_image(base64_data)